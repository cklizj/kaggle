# Hull Tactical Market Prediction - End-to-End Solution

## ğŸ¯ Overview

This repository contains a comprehensive, production-ready solution for the **Hull Tactical Market Prediction** Kaggle competition. The solution implements advanced machine learning techniques specifically designed for financial time series prediction, following best practices from champion solutions.

## ğŸ“Š Competition Details

- **Goal**: Predict market forward excess returns using Hull Tactical proprietary signals
- **Target**: `market_forward_excess_returns` (market returns minus risk-free rate)
- **Features**: 95+ proprietary signals across 7 categories (Discrete, Economic, Interest, Momentum, Price, Sentiment, Volatility)
- **Data**: Time series data with ~9,000 training samples and sequential test data

## ğŸš€ Solution Architecture

### 1. **Data Exploration & EDA**
- Automated exploratory data analysis with comprehensive visualizations
- Feature group analysis and correlation matrices
- Missing value patterns and data quality assessment
- Target variable distribution and time series analysis

### 2. **Advanced Feature Engineering**
- **Lagged Features**: Multiple time lags (1, 2, 3, 5, 10, 20 periods)
- **Rolling Statistics**: Mean, std, min, max, skewness, kurtosis across multiple windows
- **Technical Indicators**: MACD, RSI, Bollinger Bands, ATR using TA-Lib
- **Signal Interactions**: Cross-feature combinations between different signal groups
- **Polynomial Features**: Squared and cubic terms for key signals
- **Denoising**: PCA/ICA to reduce noise and handle regime shifts
- **Normalization**: RobustScaler for outlier-resistant scaling

### 3. **Walk-Forward Validation**
- Time-series aware cross-validation to prevent data leakage
- 5-fold walk-forward splits with gap periods
- Simulates real trading conditions and regime changes
- Ensures robust model evaluation

### 4. **Model Ensemble**
- **Gradient Boosting**: LightGBM, XGBoost, CatBoost with optimized parameters
- **Neural Networks**: Dense and LSTM architectures with batch normalization
- **Linear Models**: Ridge, Lasso, ElasticNet for baseline performance
- **Statistical Models**: Random Forest for feature importance analysis

### 5. **Hyperparameter Optimization**
- Optuna-based automated tuning for all models
- Bayesian optimization with pruning for efficiency
- Cross-validation aware optimization to prevent overfitting
- Parallel execution support for faster optimization

### 6. **Ensemble Stacking**
- **Weighted Blending**: Performance-based model weighting
- **Stacking**: Meta-model (Ridge regression) for prediction combination
- **Optimized Weights**: Scipy optimization for optimal blend weights
- **Multiple Methods**: Simple average, weighted average, and stacking

### 7. **Submission Generation**
- Kaggle-compatible CSV format
- Proper handling of scored vs unscored test samples
- Prediction statistics and validation
- Ready for immediate submission

## ğŸš€ Quick Start

### Option 1: UV Setup (Recommended - Much Faster!)
```bash
# One-command setup with uv
./setup_uv.sh

# Or manual uv setup:
uv venv hull_tactical_env
source hull_tactical_env/bin/activate
uv pip install pandas numpy matplotlib seaborn scikit-learn lightgbm xgboost catboost tensorflow optuna "optuna-integration[lightgbm]" TA-Lib jupyter ipykernel notebook tqdm
```

### Option 2: Traditional pip Setup
```bash
# Create virtual environment
python -m venv hull_tactical_env

# Activate environment
# On Windows:
hull_tactical_env\Scripts\activate
# On macOS/Linux:
source hull_tactical_env/bin/activate

# Install dependencies
pip install -r requirements.txt
```

## ğŸ“ File Structure

```
hull-tactical-market-prediction/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ hull_tactical_prediction.ipynb      # Main solution notebook
â”œâ”€â”€ train.csv                          # Training data
â”œâ”€â”€ test.csv                           # Test data
â”œâ”€â”€ submission.csv                     # Generated submission file
â”œâ”€â”€ setup_uv.sh                        # UV setup script (fast!)
â”œâ”€â”€ requirements.txt                    # Traditional pip requirements
â””â”€â”€ pyproject.toml                      # UV project configuration
```

## ğŸ”§ Key Classes & Components

### `HullTacticalFeatureEngineer`
- Comprehensive feature engineering pipeline
- Handles lagged features, rolling statistics, technical indicators
- Creates interaction and polynomial features
- Applies denoising and normalization

### `WalkForwardValidator`
- Time-series cross-validation implementation
- Prevents data leakage with proper time splits
- Supports multiple validation strategies

### `ModelEnsemble`
- Manages multiple model types and training
- Handles gradient boosting, neural networks, and linear models
- Tracks feature importance across models

### `HyperparameterOptimizer`
- Optuna-based optimization for all models
- Efficient Bayesian optimization with pruning
- Cross-validation aware parameter tuning

### `EnsembleStacker`
- Advanced ensemble methods (stacking, blending)
- Dynamic weight calculation based on validation performance
- Multiple combination strategies

## ğŸ† Key Features

### **Financial ML Best Practices**
- âœ… Walk-forward validation prevents data leakage
- âœ… Multiple time horizons capture different market patterns
- âœ… Feature interactions between signal groups
- âœ… Robust scaling handles outliers and regime changes
- âœ… Ensemble diversity handles different market conditions

### **Production Ready**
- âœ… Modular, reusable code architecture
- âœ… Comprehensive error handling and edge cases
- âœ… Memory efficient feature engineering
- âœ… Reproducible results with fixed random seeds
- âœ… Scalable for large datasets

### **Advanced Techniques**
- âœ… PCA/ICA denoising for regime shift robustness
- âœ… Technical indicators using TA-Lib
- âœ… Neural network architectures with proper regularization
- âœ… Bayesian hyperparameter optimization
- âœ… Multiple ensemble combination methods

## ğŸš€ Usage Instructions

### **Quick Start**
1. Open `hull_tactical_prediction.ipynb` in Jupyter/Kaggle
2. Run all cells sequentially
3. Uncomment hyperparameter optimization for best performance
4. Generate final submission using ensemble predictions

### **Customization**
- Modify feature engineering parameters in `HullTacticalFeatureEngineer`
- Adjust validation strategy in `WalkForwardValidator`
- Add new models to `ModelEnsemble`
- Customize ensemble weights in `EnsembleStacker`

### **Performance Tuning**
- Increase `n_trials` in `HyperparameterOptimizer` for better optimization
- Add more feature interactions in feature engineering
- Experiment with different ensemble weighting methods
- Monitor validation performance across different market regimes

## ğŸ“ˆ Expected Performance

### **Validation Metrics**
- **RMSE**: Optimized for regression accuracy
- **MAE**: Robust to outliers
- **Correlation**: High correlation with actual returns
- **Sharpe Ratio**: Risk-adjusted performance

### **Leaderboard Strategy**
- **Public/Private Stability**: Consistent performance across splits
- **Regime Robustness**: Handles different market conditions
- **Feature Stability**: Consistent feature importance over time
- **Prediction Distribution**: Realistic return predictions

## ğŸ”„ Continuous Improvement

### **Monitoring**
- Track feature importance changes over time
- Monitor model performance degradation
- Analyze prediction distribution shifts
- Validate against new market regimes

### **Enhancement**
- Add more sophisticated technical indicators
- Implement dynamic feature selection
- Experiment with transformer architectures
- Add regime detection and adaptive models

## ğŸ… Competition Tips

### **Winning Strategies**
1. **Feature Engineering**: Cross-signal interactions often provide alpha
2. **Model Diversity**: Different algorithms excel in different regimes
3. **Validation**: Robust walk-forward validation prevents overfitting
4. **Ensemble**: Multiple combination methods maximize robustness
5. **Optimization**: Careful hyperparameter tuning improves performance

### **Common Pitfalls**
- âŒ Data leakage from future information
- âŒ Overfitting to specific market regimes
- âŒ Ignoring feature interactions
- âŒ Single model reliance
- âŒ Insufficient validation strategy

## ğŸ“š Dependencies

```python
# Core ML Libraries
pandas, numpy, matplotlib, seaborn
scikit-learn, scipy

# Gradient Boosting
lightgbm, xgboost, catboost

# Neural Networks
tensorflow, keras

# Optimization
optuna

# Technical Analysis
talib

# Additional
warnings, random
```

## ğŸ¯ Results Summary

This solution provides:
- **Comprehensive Pipeline**: End-to-end from data loading to submission
- **Advanced Features**: 200+ engineered features from original signals
- **Robust Validation**: Walk-forward validation prevents overfitting
- **Model Diversity**: 7+ different algorithms in ensemble
- **Production Ready**: Modular, scalable, and maintainable code
- **Competition Ready**: Implements champion solution techniques

## ğŸ“ Support

For questions or improvements:
- Review the detailed comments in the notebook
- Check the leaderboard strategy section for tips
- Experiment with different parameter combinations
- Monitor validation performance carefully

---

**Good luck with your submission! ğŸ†**

*This solution implements advanced financial ML techniques and should provide competitive performance on the Hull Tactical Market Prediction leaderboard.*
